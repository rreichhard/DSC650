{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jewish-nature",
   "metadata": {},
   "source": [
    "## 3.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compatible-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from jsonschema import validate\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow as pa\n",
    "from pyarrow.json import read_json\n",
    "import pyarrow.parquet as pq\n",
    "import fastavro\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "from genson import SchemaBuilder\n",
    "import genson\n",
    "from fastavro import writer, reader, parse_schema\n",
    "from pygeohash import distances\n",
    "\n",
    "\n",
    "\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_jsonl_data():\n",
    "    src_data_path = 'routes.jsonl.gz'\n",
    "    with gzip.open(src_data_path, 'rb') as f:\n",
    "        records = [json.loads(line) for line in f.readlines()]\n",
    "    return records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = read_jsonl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efficient-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_builder = SchemaBuilder()\n",
    "for item in records:\n",
    "    schema_builder.add_schema(item)\n",
    "    \n",
    "schema = schema_builder.to_schema()\n",
    "with open('routes-schema.json', \"r\") as f:\n",
    "    existing_data = json.load(f)\n",
    "    \n",
    "existing_data[\"schema\"] = schema\n",
    "\n",
    "with open('routes-schema.json',\"w\") as f:\n",
    "    json.dump(existing_data, f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "median-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    with open('routes-schema.json') as f:\n",
    "        schema = json.load(f)\n",
    "    \n",
    "    validation_csv_path = str(current_dir)+'/results/validations.csv'\n",
    "        \n",
    "    with open(validation_csv_path, 'w') as f:    \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                validate(i, schema=schema)\n",
    "                pass\n",
    "            except ValidationError as e:\n",
    "                print(\"Invalid JSON record\")\n",
    "                pass\n",
    "            \n",
    "\n",
    "validate_jsonl_data(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-mexican",
   "metadata": {},
   "source": [
    "## 3.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescription-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path = schema_dir.joinpath('routes.avsc')\n",
    "data_path = results_dir.joinpath('routes.avro')\n",
    "\n",
    "def create_avro_dataset(records):\n",
    "    \n",
    "    with open('routes.avsc', \"r\") as f:\n",
    "        schema = json.load(f)\n",
    "    \n",
    "    parsed_schema = parse_schema(schema)\n",
    "    \n",
    "    with open(data_path, \"wb\") as f_out:\n",
    "        writer(f_out,parsed_schema,records)\n",
    "    \n",
    "        \n",
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-business",
   "metadata": {},
   "source": [
    "## 3.1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ready-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parquet_dataset():\n",
    "    src_data_path = 'routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "#     s3 = s3fs.S3FileSystem(\n",
    "#         anon=True,\n",
    "#         client_kwargs={\n",
    "#             'endpoint_url': endpoint_url\n",
    "#         }\n",
    "#     )\n",
    "    \n",
    "    with gzip.open(src_data_path, 'rb') as f:\n",
    "        table = read_json(f)\n",
    "        pq.write_table(table,parquet_output_path)\n",
    "\n",
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acknowledged-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 airline  \\\n",
      "0      {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
      "1      {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
      "2      {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
      "3      {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
      "4      {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
      "...                                                  ...   \n",
      "67658  {'airline_id': 4178, 'name': 'Regional Express...   \n",
      "67659  {'airline_id': 19016, 'name': 'Apache Air', 'a...   \n",
      "67660  {'airline_id': 19016, 'name': 'Apache Air', 'a...   \n",
      "67661  {'airline_id': 19016, 'name': 'Apache Air', 'a...   \n",
      "67662  {'airline_id': 19016, 'name': 'Apache Air', 'a...   \n",
      "\n",
      "                                             src_airport  \\\n",
      "0      {'airport_id': 2965.0, 'name': 'Sochi Internat...   \n",
      "1      {'airport_id': 2966.0, 'name': 'Astrakhan Airp...   \n",
      "2      {'airport_id': 2966.0, 'name': 'Astrakhan Airp...   \n",
      "3      {'airport_id': 2968.0, 'name': 'Chelyabinsk Ba...   \n",
      "4      {'airport_id': 2968.0, 'name': 'Chelyabinsk Ba...   \n",
      "...                                                  ...   \n",
      "67658  {'airport_id': 6334.0, 'name': 'Whyalla Airpor...   \n",
      "67659  {'airport_id': 4029.0, 'name': 'Domodedovo Int...   \n",
      "67660  {'airport_id': 2912.0, 'name': 'Manas Internat...   \n",
      "67661  {'airport_id': 2912.0, 'name': 'Manas Internat...   \n",
      "67662  {'airport_id': 2913.0, 'name': 'Osh Airport', ...   \n",
      "\n",
      "                                             dst_airport  codeshare equipment  \n",
      "0      {'airport_id': 2990.0, 'name': 'Kazan Internat...      False     [CR2]  \n",
      "1      {'airport_id': 2990.0, 'name': 'Kazan Internat...      False     [CR2]  \n",
      "2      {'airport_id': 2962.0, 'name': 'Mineralnyye Vo...      False     [CR2]  \n",
      "3      {'airport_id': 2990.0, 'name': 'Kazan Internat...      False     [CR2]  \n",
      "4      {'airport_id': 4078.0, 'name': 'Tolmachevo Air...      False     [CR2]  \n",
      "...                                                  ...        ...       ...  \n",
      "67658  {'airport_id': 3341.0, 'name': 'Adelaide Inter...      False     [SF3]  \n",
      "67659  {'airport_id': 2912.0, 'name': 'Manas Internat...      False     [734]  \n",
      "67660  {'airport_id': 4029.0, 'name': 'Domodedovo Int...      False     [734]  \n",
      "67661  {'airport_id': 2913.0, 'name': 'Osh Airport', ...      False     [734]  \n",
      "67662  {'airport_id': 2912.0, 'name': 'Manas Internat...      False     [734]  \n",
      "\n",
      "[67663 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# View the parquet data\n",
    "\n",
    "table = pq.read_table('results/routes.parquet')\n",
    "df = table.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-register",
   "metadata": {},
   "source": [
    "## 3.1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "\n",
    "def _airline_to_proto_obj(airline):\n",
    "    obj = routes_pb2.Airline()\n",
    "    if not airline.get('name'):\n",
    "        return None\n",
    "    if not airline.get('airline_id'):\n",
    "        return None\n",
    "    obj.airline_id = airline.get('airline_id')\n",
    "    if airline.get('name'):\n",
    "        obj.name = airline.get('name')\n",
    "    if airline.get('alias'):\n",
    "        obj.alias = airline.get('alias')\n",
    "    if airline.get('iata'):\n",
    "        obj.iata = airline.get('iata')\n",
    "    if airline.get('icao'):\n",
    "        obj.icao = airline.get('icao')\n",
    "    if airline.get('callsign'):\n",
    "        obj.callsign = airline.get('callsign')\n",
    "    if airline.get('country'):\n",
    "        obj.country = airline.get('country')\n",
    "    if airline.get('active'):\n",
    "        obj.active = airline.get('active')    \n",
    "\n",
    "    return obj\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        airline = _airline_to_proto_obj(record.get('airline', {}))\n",
    "        if airline:\n",
    "            route.airline.CopyFrom(airline)\n",
    "        src_airport = _airport_to_proto_obj(record.get('src_airport', {}))\n",
    "        if src_airport:\n",
    "            route.src_airport.CopyFrom(src_airport)\n",
    "        dst_airport = _airport_to_proto_obj(record.get('dst_airport', {}))\n",
    "        if dst_airport:\n",
    "            route.dst_airport.CopyFrom(dst_airport)\n",
    "        route.codeshare = record.get('codeshare', {})\n",
    "        stops = _airport_to_proto_obj(record.get('stops', {}))\n",
    "        if stops:\n",
    "            route.stops.CopyFrom(stops)\n",
    "\n",
    "\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "    \n",
    "    routes.route.append(route)\n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "    with open(compressed_path, 'wb') as f:\n",
    "        f.write(snappy.compress(routes.SerializeToString()))\n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-aquatic",
   "metadata": {},
   "source": [
    "## 3.1.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imposed-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I couldn't figure this out in time, sorry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-vitamin",
   "metadata": {},
   "source": [
    "## 3.2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pharmaceutical-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                ## TODO: use pygeohash.encode() to assign geohashes to the records and complete the hashes list\n",
    "                geo = pygeohash.encode(latitude, longitude)\n",
    "                hashes.append(geo)\n",
    "                record['geohash'] = geo\n",
    "    \n",
    "    \n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))\n",
    "            \n",
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-hearing",
   "metadata": {},
   "source": [
    "## 3.2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "circular-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_index(records):\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latit = src_airport.get('latitude')\n",
    "            longit = src_airport.get('longitude')\n",
    "        if latit and longit:\n",
    "            geo = pygeohash.encode(latit, longit)\n",
    "            hashes.append(geo)\n",
    "            record['geohash'] = geo\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    return hash_index\n",
    "\n",
    "        \n",
    "def encode_for_search(latitude, longitude):\n",
    "    target_geohash = pygeohash.encode(latitude, longitude)\n",
    "    return target_geohash\n",
    "\n",
    "distance_hashes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abandoned-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest airport is Eppley Airfield\n"
     ]
    }
   ],
   "source": [
    "def airport_search(latitude, longitude):\n",
    "    t_geohash = encode_for_search(latitude, longitude)\n",
    "    records = read_jsonl_data()\n",
    "    hashed_index = {}\n",
    "    hashed_index = create_hash_index(records)\n",
    "    for h in hashes:\n",
    "        t_distance = pygeohash.geohash_approximate_distance(t_geohash,h)\n",
    "        distance_hashes.setdefault(h,t_distance)\n",
    "    sorted_distance_hashes = sorted(distance_hashes.items(),key=lambda x:x[1],reverse=False)\n",
    "    closest_airport_geohash = sorted_distance_hashes[::len(sorted_distance_hashes)-1]\n",
    "    closest_airport_geohash = closest_airport_geohash[0]\n",
    "    closest_airport_geohash = closest_airport_geohash[0]\n",
    "    value = hashed_index[closest_airport_geohash[:3]]\n",
    "    src_airport = value[0].get('src_airport', {})\n",
    "    name = src_airport.get('name')\n",
    "#     print(closest_airport_geohash[0])\n",
    "    print(\"The closest airport is\",name)\n",
    "    \n",
    "    \n",
    "airport_search(41.1499988, -95.91779)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
